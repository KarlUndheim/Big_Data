{"cells":[{"cell_type":"markdown","source":["#### Names of people in the group\n\nPlease write the names of the people in your group in the next cell."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"bbe62928-01d3-402d-9e45-19d009a4639d"}}},{"cell_type":"markdown","source":["Name of person A Karl Edvin Undheim\n\nName of person B"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"15e1606f-bbea-4e98-9f90-bf0a15da5391"}}},{"cell_type":"code","source":["# Loading modules that we need\nfrom pyspark.sql.session import SparkSession\nfrom pyspark.sql.types import *\nfrom pyspark.sql.functions import *\n\n# Add your imports below this line"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"389ff132-7e3c-444e-a980-6490e3448153"}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# A helper function to load a table (stored in Parquet format) from DBFS as a Spark DataFrame \ndef load_df(table_name: \"name of the table to load\") -> DataFrame:\n    return spark.read.parquet(table_name)\n\nusers_df = load_df(\"/user/hive/warehouse/users\")\nposts_df = load_df(\"/user/hive/warehouse/posts\")\n\n# Uncomment if you need\n# comments_df = load_df(\"/user/hive/warehouse/comments\")\n# badges_df = load_df(\"/user/hive/warehouse/badges\")"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1b384d61-f63a-4c3f-9d87-63e0427c5ecd"}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### The problem: mining the interests of experts\n\nThe primary role of a questions and answering platform such as Stack Exchange is to connect two types of people. Namely, people who have questions in areas such as computer science or data science and knowledgeable people who can answer those questions reliably. Let's call the first category of people' knowledge seekers' and the second one 'expert users' or 'experts' for short.\n\nHere we want to answer a question related to the diversity of topics that experts are interested in using our data. We want to know if expert users only answer questions in a specific set of topics or their interests include a wide variety of topics.\n\nTo answer the above question, we will compute the correlation between a user's expertise level and the diversity of topics of questions they have answered. The first step is to define two variables (or measures); first for 'user expertise level' and then for 'user interest diversity'. Then we will use the Pearson correlation coefficient to measure the linear correlation between the two variables. We define the variables as:\n\n   - VariableA (the measure of user expertise level). We will use the 'Reputation' column from 'users' table, which according to Stack Exchange's documentation \"is a rough measurement of how much the community trusts you; it is earned by convincing your peers that you know what you're talking about\" as an indicator of a user's expertise level on the platform. \n\n   - VariableB (The measure of user interest diversity). We measure the diversity of a user's interests by computing the total number of distinct tags associated with the questions each user has answered divided by the total number of unique tags which is 638.\n\nCompute the Pearson correlation coefficient between VariableA and VariableB, and based on the result you've got, answer the following question: \n\n     Do expert users have specif interests or do they have general interests?\n\nPlease explain your reasoning on how you reached your answer.\n\nYou should use Apache Spark API for your implementation. You can use the Spark implementation of the Pearson correlation coefficient."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e9b9e457-0510-45fb-8a13-85c006247f0c"}}},{"cell_type":"code","source":["# I make tempviews to use them in queries\nusers_df.createOrReplaceTempView('users')\nposts_df.createOrReplaceTempView('posts')\n\n# First I make a dataframe with the user Id in one column and Tags in the other. A row shows the user Id and every tag associated with a specific question the user has answered. There is one record for every answer, so one user can be in multiple records.\n\n# This can be done in a query. I make a table with user Ids and every parentId of the questions they have answered. This table is then joined with posts on user Id to get the tags for the question. Finally I select user Id and Tags from this table.\n\nuser_tags_query = \"SELECT C.Id, posts.Tags FROM (SELECT users.Id, posts.parentId FROM users INNER JOIN posts ON users.Id==posts.OwnerUserId WHERE posts.PostTypeId==2) C INNER JOIN posts ON C.parentId==posts.Id SORT BY C.Id ASC\"\n\ndf1 = spark.sql(user_tags_query)\ndf1.show()\n\n# This is shown below:"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a5d203e1-ee4f-4ffe-902b-621c027cff89"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+--------------------+\n| Id|                Tags|\n+---+--------------------+\n|  9|<bigdata><scalabi...|\n|  9|<recommender-syst...|\n| 11|<bigdata><apache-...|\n| 11|    <classification>|\n| 14|<bigdata><scalabi...|\n| 14|<data-mining><clu...|\n| 14|<bigdata><statist...|\n| 14|<nlp><topic-model...|\n| 14|<classification><...|\n| 14|               <svm>|\n| 14|   <r><dataset><pca>|\n| 14|<machine-learning...|\n| 14|<data-cleaning><l...|\n| 14|<r><classificatio...|\n| 14|<machine-learning...|\n| 17|<machine-learning...|\n| 17|      <keras><tools>|\n| 17|<machine-learning...|\n| 21|<machine-learning...|\n| 21|<bigdata><google>...|\n+---+--------------------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+--------------------+\n| Id|                Tags|\n+---+--------------------+\n|  9|<bigdata><scalabi...|\n|  9|<recommender-syst...|\n| 11|<bigdata><apache-...|\n| 11|    <classification>|\n| 14|<bigdata><scalabi...|\n| 14|<data-mining><clu...|\n| 14|<bigdata><statist...|\n| 14|<nlp><topic-model...|\n| 14|<classification><...|\n| 14|               <svm>|\n| 14|   <r><dataset><pca>|\n| 14|<machine-learning...|\n| 14|<data-cleaning><l...|\n| 14|<r><classificatio...|\n| 14|<machine-learning...|\n| 17|<machine-learning...|\n| 17|      <keras><tools>|\n| 17|<machine-learning...|\n| 21|<machine-learning...|\n| 21|<bigdata><google>...|\n+---+--------------------+\nonly showing top 20 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Now we need to count how many distinct tags are associated with each user. To do this I first expand the table such that every user-tag pairing is a record. This is done by replacing >< with >==< so that I can split a tag string between separate tags. Then I use sparks explode function and split on ==.\ndf1 = df1.withColumn('Tags', regexp_replace('Tags', '><', '>==<')).withColumn(\"Tags\", explode(split(\"Tags\", \"==\")))\n\ndf1.show()\ndf1.createOrReplaceTempView('df1')\n\n# Now I count how many distinct tags are associated with each user with a simple query:\nuser_tagCount_query = \"SELECT df1.Id, COUNT(DISTINCT df1.Tags) AS TagCount FROM df1 GROUP BY df1.Id\"\n\ndf2 = spark.sql(user_tagCount_query)\ndf2.show()\n\ndf2.createOrReplaceTempView('df2')"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"717b4686-f208-468f-a43b-4f171baeea2e"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+---+--------------------+\n| Id|                Tags|\n+---+--------------------+\n|  9|           <bigdata>|\n|  9|       <scalability>|\n|  9|        <efficiency>|\n|  9|       <performance>|\n|  9|<recommender-system>|\n|  9|<information-retr...|\n| 11|           <bigdata>|\n| 11|     <apache-hadoop>|\n| 11|    <classification>|\n| 14|           <bigdata>|\n| 14|       <scalability>|\n| 14|        <efficiency>|\n| 14|       <performance>|\n| 14|       <data-mining>|\n| 14|        <clustering>|\n| 14|            <octave>|\n| 14|           <k-means>|\n| 14|  <categorical-data>|\n| 14|           <bigdata>|\n| 14|        <statistics>|\n+---+--------------------+\nonly showing top 20 rows\n\n+-----+--------+\n|   Id|TagCount|\n+-----+--------+\n|13285|      16|\n|43527|       4|\n|50223|       5|\n|57693|       5|\n|46465|       3|\n|69478|      66|\n|  471|      56|\n|45615|      10|\n|49717|       5|\n|27760|       7|\n|91299|       5|\n|29054|       4|\n|11141|      19|\n| 9465|      11|\n|80579|       3|\n|85321|       4|\n|74852|       4|\n|29744|       2|\n|92080|       2|\n|90817|       3|\n+-----+--------+\nonly showing top 20 rows\n\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+---+--------------------+\n| Id|                Tags|\n+---+--------------------+\n|  9|           <bigdata>|\n|  9|       <scalability>|\n|  9|        <efficiency>|\n|  9|       <performance>|\n|  9|<recommender-system>|\n|  9|<information-retr...|\n| 11|           <bigdata>|\n| 11|     <apache-hadoop>|\n| 11|    <classification>|\n| 14|           <bigdata>|\n| 14|       <scalability>|\n| 14|        <efficiency>|\n| 14|       <performance>|\n| 14|       <data-mining>|\n| 14|        <clustering>|\n| 14|            <octave>|\n| 14|           <k-means>|\n| 14|  <categorical-data>|\n| 14|           <bigdata>|\n| 14|        <statistics>|\n+---+--------------------+\nonly showing top 20 rows\n\n+-----+--------+\n|   Id|TagCount|\n+-----+--------+\n|13285|      16|\n|43527|       4|\n|50223|       5|\n|57693|       5|\n|46465|       3|\n|69478|      66|\n|  471|      56|\n|45615|      10|\n|49717|       5|\n|27760|       7|\n|91299|       5|\n|29054|       4|\n|11141|      19|\n| 9465|      11|\n|80579|       3|\n|85321|       4|\n|74852|       4|\n|29744|       2|\n|92080|       2|\n|90817|       3|\n+-----+--------+\nonly showing top 20 rows\n\n"]}}],"execution_count":0},{"cell_type":"code","source":["# Now I select TagCount from df2 and convert it to diversity by dividing by 638(total amount of distinct tags), and Reputation from users. \n# This is our final table which can be used in the pearson calculation.\nq = \"SELECT TagCount/638 AS Diversity, Reputation FROM df2 INNER JOIN users ON df2.Id==users.Id SORT BY Diversity DESC\"\n\ndf3 = spark.sql(q)\ndf3.show()\n\nr1 = df3.corr(\"Diversity\", \"Reputation\")\nprint(r1)\n\n# Do expert users have specif interests or do they have general interests?\n# Answer:\n# The correlation coefficient is about 0.72, which generally means a strong correlation. \n# So there is a strong correlation between a users reputation and the number of distinct tags associated with the questions the user has answered.\n# This means an expert user has general interests."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"29b84400-d5c3-4750-9dec-05a8a2c96d9b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"+-------------------+----------+\n|          Diversity|Reputation|\n+-------------------+----------+\n|0.48746081504702193|     10037|\n|0.46551724137931033|     10346|\n|0.32445141065830724|     11711|\n|0.31347962382445144|      8206|\n| 0.3056426332288401|      4782|\n|0.30094043887147337|      2899|\n|0.28213166144200624|      6349|\n| 0.2664576802507837|      4611|\n| 0.2476489028213166|     24229|\n|0.24294670846394983|      4083|\n|0.23981191222570533|     11793|\n| 0.2335423197492163|      4549|\n| 0.2225705329153605|      4679|\n| 0.2225705329153605|      4109|\n|0.21786833855799373|      5211|\n|0.21630094043887146|      7044|\n| 0.2115987460815047|      7248|\n| 0.2115987460815047|      7613|\n|0.21003134796238246|      9821|\n| 0.2084639498432602|       674|\n+-------------------+----------+\nonly showing top 20 rows\n\n0.7217677648622982\n","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"ansi","arguments":{}}},"output_type":"display_data","data":{"text/plain":["+-------------------+----------+\n|          Diversity|Reputation|\n+-------------------+----------+\n|0.48746081504702193|     10037|\n|0.46551724137931033|     10346|\n|0.32445141065830724|     11711|\n|0.31347962382445144|      8206|\n| 0.3056426332288401|      4782|\n|0.30094043887147337|      2899|\n|0.28213166144200624|      6349|\n| 0.2664576802507837|      4611|\n| 0.2476489028213166|     24229|\n|0.24294670846394983|      4083|\n|0.23981191222570533|     11793|\n| 0.2335423197492163|      4549|\n| 0.2225705329153605|      4679|\n| 0.2225705329153605|      4109|\n|0.21786833855799373|      5211|\n|0.21630094043887146|      7044|\n| 0.2115987460815047|      7248|\n| 0.2115987460815047|      7613|\n|0.21003134796238246|      9821|\n| 0.2084639498432602|       674|\n+-------------------+----------+\nonly showing top 20 rows\n\n0.7217677648622982\n"]}}],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Task4","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":847488228102811}},"nbformat":4,"nbformat_minor":0}
